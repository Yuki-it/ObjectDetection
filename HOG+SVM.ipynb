{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # path setting\n",
    "    common_path = 'C:\\\\Users\\\\yukir\\\\anaconda3\\\\envs\\\\opencv\\\\Lib\\\\site-packages\\\\cv2\\\\data'\n",
    "    pedestrianPath='C:\\\\Users\\\\yukir\\\\workspace\\\\opencv_work\\\\Vehicle-And-Pedestrian-Detection-Using-Haar-Cascades\\\\Main Project\\\\Main Project\\\\Pedestrian Detection'\n",
    "\n",
    "    # 画像の読み込み\n",
    "\n",
    "    # 使用ファイルと入出力ディレクトリ\n",
    "\n",
    "    image_path = os.path.join(pedestrianPath,\"pedestrian_sample.jpg\")\n",
    "    output_path =os.path.join(pedestrianPath, \".\\\\outputs\\\\\") + \"test3.jpg\"    \n",
    "    \n",
    "    im = cv2.imread(image_path)\n",
    "    # HoG特徴量の計算\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    #hog = cv2.HOGDescriptor((48,96), (16,16), (8,8), (8,8), 9)\n",
    "    \n",
    "    # SVMによる人検出\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    #hog.setSVMDetector(cv2.HOGDescriptor_getDaimlerPeopleDetector())\n",
    "    \n",
    "    #hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05}\n",
    "    hogParams = {'hitThreshold':0,'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05,'finalThreshold':2}\n",
    "    \n",
    "    # 人を検出した座標\n",
    "    ##image_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    human, r = hog.detectMultiScale(im, **hogParams)\n",
    "    # 長方形で人を囲う\n",
    "    for (x, y, w, h) in human:\n",
    "        cv2.rectangle(im, (x, y),(x+w, y+h),(0,50,255), 2)\n",
    "    # 人を検出した座標\n",
    "    cv2.imshow(\"Human detection\",im)\n",
    "    cv2.waitKey(0)\n",
    "    # 画像保存\n",
    "    cv2.imwrite(output_path,im)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply NMS(Non-Maximum-Suppression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from __future__ import print_function\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "# path setting\n",
    "common_path = 'C:\\\\Users\\\\yukir\\\\anaconda3\\\\envs\\\\opencv\\\\Lib\\\\site-packages\\\\cv2\\\\data'\n",
    "pedestrianPath='C:\\\\Users\\\\yukir\\\\workspace\\\\opencv_work\\\\Vehicle-And-Pedestrian-Detection-Using-Haar-Cascades\\\\Main Project\\\\Main Project\\\\Pedestrian Detection'\n",
    "\n",
    "# 画像の読み込み\n",
    "\n",
    "# 使用ファイルと入出力ディレクトリ\n",
    "\n",
    "image_path = os.path.join(pedestrianPath,\"pedestrian_sample.jpg\")\n",
    "output_path =os.path.join(pedestrianPath, \".\\\\outputs\\\\\") + \"test3.jpg\"    \n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-i\", \"--images\", required=True, help=image_path)\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# initialize the HOG descriptor/person detector\n",
    "\n",
    "hog = cv2.HOGDescriptor((48,96), (16,16), (8,8), (8,8), 9)\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDaimlerPeopleDetector())\n",
    "\n",
    "#hog = cv2.HOGDescriptor() \n",
    "#hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    \n",
    "# loop over the image paths\n",
    "\n",
    "# load the image and resize it to (1) reduce detection time\n",
    "# and (2) improve detection accuracy\n",
    "image = cv2.imread(image_path)\n",
    "image = imutils.resize(image, width=min(400, image.shape[1]))\n",
    "orig = image.copy()\n",
    "\n",
    "# detect people in the image\n",
    "hogParams = {'hitThreshold':0,'winStride': (8,8), 'padding': (0,0), 'scale': 1.05,'finalThreshold':0}\n",
    "#image_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "(rects, weights) = hog.detectMultiScale(image, **hogParams)\n",
    "# draw the original bounding boxes\n",
    "for (x, y, w, h) in rects:\n",
    "    cv2.rectangle(orig, (x, y), (x + w, y + h), (0,50,255), 2)\n",
    "# apply non-maxima suppression to the bounding boxes using a\n",
    "# fairly large overlap threshold to try to maintain overlapping\n",
    "# boxes that are still people\n",
    "rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "# draw the final bounding boxes\n",
    "for (xA, yA, xB, yB) in pick:\n",
    "    cv2.rectangle(image, (xA, yA), (xB, yB), (0,50,255), 2)\n",
    "# show some information on the number of bounding boxes\n",
    "\n",
    "# show the output images\n",
    "cv2.imshow(\"Before NMS\", orig)\n",
    "cv2.imshow(\"After NMS\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from __future__ import print_function\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "# path setting\n",
    "common_path = 'C:\\\\Users\\\\yukir\\\\anaconda3\\\\envs\\\\opencv\\\\Lib\\\\site-packages\\\\cv2\\\\data'\n",
    "pedestrianPath='C:\\\\Users\\\\yukir\\\\workspace\\\\opencv_work\\\\Vehicle-And-Pedestrian-Detection-Using-Haar-Cascades\\\\Main Project\\\\Main Project\\\\Pedestrian Detection'\n",
    "\n",
    "# 画像の読み込み\n",
    "\n",
    "# 使用ファイルと入出力ディレクトリ\n",
    "\n",
    "image_path = os.path.join(pedestrianPath,\"pedestrian_sample.jpg\")\n",
    "output_path =os.path.join(pedestrianPath, \".\\\\outputs\\\\\") + \"test3.jpg\"    \n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-i\", \"--images\", required=True, help=image_path)\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# initialize the HOG descriptor/person detector\n",
    "\n",
    "hog = cv2.HOGDescriptor((48,96), (16,16), (8,8), (8,8), 9)\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDaimlerPeopleDetector())\n",
    "\n",
    "#hog = cv2.HOGDescriptor() \n",
    "#hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    \n",
    "# loop over the image paths\n",
    "\n",
    "# load the image and resize it to (1) reduce detection time\n",
    "# and (2) improve detection accuracy\n",
    "image = cv2.imread(image_path)\n",
    "image = imutils.resize(image, width=min(400, image.shape[1]))\n",
    "orig = image.copy()\n",
    "\n",
    "# detect people in the image\n",
    "hogParams = {'hitThreshold':0,'winStride': (8,8), 'padding': (0,0), 'scale': 1.05,'finalThreshold':0}\n",
    "#image_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "(rects, weights) = hog.detectMultiScale(image, **hogParams)\n",
    "# draw the original bounding boxes\n",
    "for (x, y, w, h) in rects:\n",
    "    cv2.rectangle(orig, (x, y), (x + w, y + h), (0,50,255), 2)\n",
    "# apply non-maxima suppression to the bounding boxes using a\n",
    "# fairly large overlap threshold to try to maintain overlapping\n",
    "# boxes that are still people\n",
    "rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "# draw the final bounding boxes\n",
    "for (xA, yA, xB, yB) in pick:\n",
    "    cv2.rectangle(image, (xA, yA), (xB, yB), (0,50,255), 2)\n",
    "# show some information on the number of bounding boxes\n",
    "\n",
    "# show the output images\n",
    "cv2.imshow(\"Before NMS\", orig)\n",
    "cv2.imshow(\"After NMS\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
